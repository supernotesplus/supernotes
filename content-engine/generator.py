import csv
import os
import random
import json
from datetime import datetime
from slugify import slugify # Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø³ØªÙ‚ÙˆÙ… Ø¨ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø¥Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¡ Ù…Ù„ÙØ§Øª URL Ø¢Ù…Ù†Ø©

# ----------------------------------------------------
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
# ----------------------------------------------------
CONFIG_FILE = 'content-engine/config.json'
CONTENT_DIR = 'content/posts'
BLOCKS_DIR = 'blocks'

def load_config():
    """ØªØ­Ù…ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ù…Ù‚ ÙˆØ§Ù„Ø­Ø¯ Ø§Ù„ÙŠÙˆÙ…ÙŠ Ù…Ù† config.json"""
    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            config = json.load(f)
        return config
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£: ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ config.json: {e}")
        return None

def load_blocks(section_name):
    """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨Ù„ÙˆÙƒØ§Øª Ù…Ù† Ù…Ù„Ù Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø­Ø¯Ø¯"""
    filepath = os.path.join(BLOCKS_DIR, f'{section_name}.txt')
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… list comprehension Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ÙØ§Ø±ØºØ©
            blocks = [line.strip() for line in f if line.strip()]
        return blocks
    except FileNotFoundError:
        print(f"âš ï¸ ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ø¨Ù„ÙˆÙƒØ§Øª: {filepath}")
        return []

def generate_article(keyword, title, blocks_map, depth_config):
    """ØªÙˆÙ„ÙŠØ¯ Ù…Ù‚Ø§Ù„ ÙˆØ§Ø­Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ù„ÙˆÙƒØ§Øª ÙˆØ¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ù…Ù‚"""
    
    # ----------------------------------------------------
    # 2. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… random.sample Ù„ÙØ±Ø¶ Ø§Ù„Ø¹Ù…Ù‚)
    # ----------------------------------------------------
    
    # Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯Ù‡ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ù„
    section_order = ['intros', 'explanations', 'pros', 'cons', 'steps', 'tips', 'cta']
    
    article_content = []

    for section in section_order:
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ù…Ù‚ (Ø¹Ø¯Ø¯ Ø§Ù„Ø¨Ù„ÙˆÙƒØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø³Ø­Ø¨Ù‡Ø§) Ù…Ù† config.json
        required_depth = depth_config.get(section, 1) # Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù‡Ùˆ 1 Ø¥Ø°Ø§ Ù„Ù… ÙŠØ¬Ø¯ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯
        
        available_blocks = blocks_map.get(section, [])
        
        if not available_blocks:
            continue
        
        # Ù†Ø³ØªØ®Ø¯Ù… random.sample Ù„Ø§Ø®ØªÙŠØ§Ø± Ø¹Ø¯Ø¯ Ù…Ø¹ÙŠÙ† Ù…Ù† Ø§Ù„Ø¨Ù„ÙˆÙƒØ§Øª
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¹Ù…Ù‚ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø£ÙƒØ¨Ø± Ù…Ù† Ø§Ù„Ø¨Ù„ÙˆÙƒØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©ØŒ Ù†Ø®ØªØ§Ø± ÙƒÙ„ Ø§Ù„Ù…ØªØ§Ø­
        num_blocks_to_select = min(required_depth, len(available_blocks))
        
        if num_blocks_to_select == 0:
            continue
            
        selected_blocks = random.sample(available_blocks, num_blocks_to_select)
        
        # 3. ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù„Ù€ Markdown
        
        # Ø¥Ø¶Ø§ÙØ© Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù‚Ø³Ù… (Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© ÙˆØ§Ù„Ø®Ø§ØªÙ…Ø©)
        if section not in ['intros', 'cta']:
            # Ù†Ø­ÙˆÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø¥Ù„Ù‰ Ø¹Ù†Ø§ÙˆÙŠÙ† Ù…Ù‚Ø±ÙˆØ¡Ø© (Ù…Ø«Ù„: steps -> Practical Steps)
            readable_title = {
                'explanations': 'Key Explanations and Context',
                'pros': 'Benefits and Advantages',
                'cons': 'Challenges and Considerations',
                'steps': 'Practical Steps To Implement',
                'tips': 'Expert Tips And Insights',
            }.get(section, section.capitalize())
            
            article_content.append(f'\n## {readable_title}\n')
            
        # Ø¯Ù…Ø¬ Ø§Ù„Ø¨Ù„ÙˆÙƒØ§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
        # ÙƒÙ„ Ø¨Ù„ÙˆÙƒ ÙŠØªÙ… ÙˆØ¶Ø¹Ù‡ ÙÙŠ ÙÙ‚Ø±Ø© Ù…Ù†ÙØµÙ„Ø©
        for block in selected_blocks:
            article_content.append(f'{block}\n')
            
    # ----------------------------------------------------
    # 4. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ Front Matter (Ø¨ÙŠØ§Ù†Ø§Øª Hugo)
    # ----------------------------------------------------
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… Ù…Ù„Ù Ø¢Ù…Ù†
    filename_slug = slugify(title)
    filename = os.path.join(CONTENT_DIR, f'{filename_slug}.md')
    
    # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ÙƒØ¹Ù„Ø§Ù…Ø§Øª (Tags)
    tags = [slugify(keyword, separator=' ')]
    
    front_matter = f"""---
title: "{title}"
date: {datetime.now().isoformat()}
draft: false
tags: {json.dumps(tags)}
keywords: ["{keyword}"]
categories: ["Knowledge"]
---
"""
    
    # 5. Ø¯Ù…Ø¬ Ø§Ù„Ù€ Front Matter ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰
    final_content = front_matter + '\n' + '\n'.join(article_content)
    
    # 6. Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(final_content)
        print(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù‚Ø§Ù„: {filename}")
        return filename
    except Exception as e:
        print(f"âŒ ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù {filename}: {e}")
        return None


def main():
    config = load_config()
    if not config:
        return

    keywords_file = os.path.join('content-engine', config.get('keywords_file', 'new_keywords.csv'))
    daily_limit = config.get('daily_limit', 1)
    depth_config = config.get('section_depth', {})
    
    # 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨Ù„ÙˆÙƒØ§Øª Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
    blocks_map = {}
    for section in depth_config.keys():
        blocks_map[section] = load_blocks(section)
        
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ©
    total_available_blocks = sum(len(blocks) for blocks in blocks_map.values())
    if total_available_blocks < 10:
        print("ğŸ›‘ ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ´ØºÙŠÙ„: Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ø¯Ø¯ ÙƒØ§ÙÙ Ù…Ù† Ø§Ù„Ø¨Ù„ÙˆÙƒØ§Øª ÙÙŠ Ù…Ø¬Ù„Ø¯ blocks/.")
        return

    # 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
    try:
        with open(keywords_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            all_keywords = list(reader)
    except FileNotFoundError:
        print(f"ğŸ›‘ ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ´ØºÙŠÙ„: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {keywords_file}")
        return

    if not all_keywords:
        print("ğŸ›‘ Ù„Ø§ ØªÙˆØ¬Ø¯ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„ØªÙˆÙ„ÙŠØ¯.")
        return

    # 3. Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ù„Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø¯ Ø§Ù„ÙŠÙˆÙ…ÙŠ
    posts_to_generate = all_keywords[:daily_limit]
    
    print(f"ğŸ“ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ {len(posts_to_generate)} Ù…Ù‚Ø§Ù„ Ù…Ù† Ø£ØµÙ„ {len(all_keywords)} Ù…ØªØ§Ø­ÙŠÙ†...")
    
    # 4. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª ÙˆØ­Ø°Ù Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ØªÙŠ ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§
    generated_count = 0
    generated_filenames = []
    
    for post in posts_to_generate:
        filename = generate_article(post['keyword'], post['title'], blocks_map, depth_config)
        if filename:
            generated_count += 1
            generated_filenames.append(filename)

    # 5. Ø­Ø°Ù Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ØªÙŠ ØªÙ… ØªÙˆÙ„ÙŠØ¯Ù‡Ø§ Ù…Ù† Ù…Ù„Ù CSV
    remaining_keywords = all_keywords[generated_count:]
    
    try:
        with open(keywords_file, 'w', encoding='utf-8', newline='') as f:
            fieldnames = ['keyword', 'title']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(remaining_keywords)
        print(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ù…Ù„Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©. ØªØ¨Ù‚Øª {len(remaining_keywords)} ÙƒÙ„Ù…Ø©.")
    except Exception as e:
        print(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ù…Ù„Ù CSV: {e}")
        
    print(f"--- Ø§Ù†ØªÙ‡Øª Ø¹Ù…Ù„ÙŠØ© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰. ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {generated_count} Ù…Ù‚Ø§Ù„. ---")


if __name__ == '__main__':
    main()
